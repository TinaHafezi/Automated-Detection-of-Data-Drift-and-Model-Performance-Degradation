import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from metrics_store import MetricsStore

def load_metrics():
    """Load metrics from SQLite database"""
    import sqlite3
    conn = sqlite3.connect("metrics.db")
    df = pd.read_sql("SELECT * FROM metrics", conn)
    conn.close()
    return df

def risk_gauge(score):
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=score,
        title={'text': "Ø§Ù…ØªÛŒØ§Ø² Ø±ÛŒØ³Ú© Ø³ÛŒØ³ØªÙ…"},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'thickness': 0.4},
            'steps': [
                {'range': [0, 30], 'color': "green"},
                {'range': [30, 60], 'color': "yellow"},
                {'range': [60, 100], 'color': "red"},
            ],
        }
    ))
    return fig


def display_drift_metrics(df):
    """Display all drift metrics in a compact view"""
    st.subheader("ğŸ“Š Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯Ø±ÛŒÙØª Ø¢Ù…Ø§Ø±ÛŒ")
    
    latest = df.sort_values("timestamp").groupby("metric_name").tail(1)
    
    # Create two columns for KS and Wasserstein
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Ø¢Ø²Ù…ÙˆÙ† Ú©ÙˆÙ„Ù…ÙˆÚ¯Ø±ÙˆÙâ€“Ø§Ø³Ù…ÛŒØ±Ù†ÙˆÙ (KS Test)**")
        ks_metrics = latest[latest["metric_name"].str.startswith("KS_")]
        if not ks_metrics.empty:
            ks_summary = []
            for _, row in ks_metrics.iterrows():
                feature = row["metric_name"].replace("ks_", "")
                value = row["value"]
                try:
                    num_val = float(value)
                    ks_summary.append({
                        "Feature": feature,
                        "KS": f"{num_val:.2e}" if num_val < 0.001 else f"{num_val:.3f}",
                        "Status": "âš ï¸" if num_val < 0.01 else "âœ…"
                    })
                except:
                    ks_summary.append({
                        "Feature": feature,
                        "KS": str(value),
                        "Status": "â“"
                    })
            
            ks_df = pd.DataFrame(ks_summary)
            st.dataframe(ks_df, height=200, use_container_width=True)
            
            # Count problematic KS values
            problematic = sum(1 for _, row in ks_metrics.iterrows() 
                            if isinstance(row["value"], (int, float, np.number)) and row["value"] < 0.01)
            if problematic > 0:
                st.error(f"{problematic} ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø§Ø®ØªÙ„Ø§Ù ØªÙˆØ²ÛŒØ¹ Ø´Ø¯ÛŒØ¯ Ù‡Ø³ØªÙ†Ø¯")

    
    with col2:
        st.write("**ÙØ§ØµÙ„Ù‡ ÙˆØ§Ø³Ø±Ø´ØªØ§ÛŒÙ† (Wasserstein Distance)**")

        wasserstein_metrics = latest[latest["metric_name"].str.startswith("WASS_")]
        if not wasserstein_metrics.empty:
            wasserstein_summary = []
            high_drift_count = 0
            
            for _, row in wasserstein_metrics.iterrows():
                feature = row["metric_name"].replace("wasserstein_", "")
                value = row["value"]
                try:
                    num_val = float(value)
                    wasserstein_summary.append({
                        "Feature": feature[:20],  # Truncate long names
                        "Distance": f"{num_val:.1f}",
                        "Status": "ğŸ”´" if num_val > 10 else "ğŸŸ¡" if num_val > 1 else "ğŸŸ¢"
                    })
                    if num_val > 10:
                        high_drift_count += 1
                except:
                    pass
            
            if wasserstein_summary:
                wasserstein_df = pd.DataFrame(wasserstein_summary)
                st.dataframe(wasserstein_df, height=200, use_container_width=True)
                
                if high_drift_count > 0:
                    st.error(f"{high_drift_count} ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø¯Ø±ÛŒÙØª Ø´Ø¯ÛŒØ¯ ÙˆØ§Ø³Ø±Ø´ØªØ§ÛŒÙ† Ù‡Ø³ØªÙ†Ø¯")

    
    # Data Quality Issues
    st.subheader("ğŸ” Ù…Ø´Ú©Ù„Ø§Øª Ú©ÛŒÙÛŒØª Ø¯Ø§Ø¯Ù‡")

    dq_col1, dq_col2 = st.columns(2)
    
    with dq_col1:
        st.write("**Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡**")
        missing_metrics = latest[latest["metric_name"].str.contains("dq_missing_")]
        if not missing_metrics.empty:
            for _, row in missing_metrics.iterrows():
                feature = row["metric_name"].replace("dq_missing_", "")
                value = row["value"]
                try:
                    if float(value) > 0:
                        st.warning(f"{feature}: {float(value):.1%} Ø¯Ø§Ø¯Ù‡ Ú¯Ù…Ø´Ø¯Ù‡")
                except:
                    pass
    
    with dq_col2:
        st.write("**Ù…Ù‚Ø§Ø¯ÛŒØ± ØµÙØ± ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ**")
        zero_metrics = latest[latest["metric_name"].str.contains("dq_zero_")]
        if not zero_metrics.empty:
            for _, row in zero_metrics.iterrows():
                feature = row["metric_name"].replace("dq_zero_", "")
                value = row["value"]
                try:
                    if float(value) > 0.1:  # More than 10% zeros
                        st.warning(f"{feature}: {float(value):.1%} Ù…Ù‚Ø¯Ø§Ø± ØµÙØ±")
                except:
                    pass
    
    # Prediction Drift
    st.subheader("ğŸ“ˆ Ø¯Ø±ÛŒÙØª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„")
    pred_metrics = latest[latest["metric_name"].str.startswith("PRED_")]
    if not pred_metrics.empty:
        pred_col1, pred_col2, pred_col3 = st.columns(3)
        
        with pred_col1:
            mean_shift = latest[latest["metric_name"] == "PRED_mean_shift"]["value"].values
            if len(mean_shift) > 0:
                try:
                    val = float(mean_shift[0])
                    st.metric("ØªØºÛŒÛŒØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", f"{val:.2f}")
                    if abs(val) > 10:
                        st.error("Ø¨Ø§ÛŒØ§Ø³ Ø´Ø¯ÛŒØ¯ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ!")
                except:
                    st.metric("Mean Shift", "N/A")
        
        with pred_col2:
            dist_shift = latest[latest["metric_name"] == "PRED_distribution_shift"]["value"].values
            if len(dist_shift) > 0:
                try:
                    val = float(dist_shift[0])
                    st.metric("ØªØºÛŒÛŒØ± ØªÙˆØ²ÛŒØ¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", f"{val:.2f}")
                    if val > 50:
                        st.error("Major shift!")
                except:
                    st.error("ØªØºÛŒÛŒØ± ØªÙˆØ²ÛŒØ¹ Ø¨Ø³ÛŒØ§Ø± Ø²ÛŒØ§Ø¯!")
        
        with pred_col3:
            conf_shift = latest[latest["metric_name"] == "PRED_confidence_shift"]["value"].values
            if len(conf_shift) > 0:
                try:
                    val = float(conf_shift[0])
                    st.metric("ØªØºÛŒÛŒØ± Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…Ø¯Ù„", f"{val:.2f}")
                except:
                    st.metric("ØªØºÛŒÛŒØ± Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…Ø¯Ù„", "N/A")

def display_performance_metrics(df):
    st.subheader("ğŸ¯ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„")
    
    latest = df.sort_values("timestamp").groupby("metric_name").tail(1)
    perf_col1, perf_col2 = st.columns(2)
    
    with perf_col1:
        # Current metrics
        current_metrics = latest[latest["metric_name"].str.startswith("current_")]
        for _, row in current_metrics.iterrows():
            metric = row["metric_name"].replace("current_", "")
            value = row["value"]
            try:
                st.metric(f"Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒ {metric}", f"{float(value):.3f}")
            except:
                st.metric(f"Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒ  {metric}", str(value))
    
    with perf_col2:
        # Drop metrics
        drop_metrics = latest[latest["metric_name"].str.startswith("drop_")]
        for _, row in drop_metrics.iterrows():
            metric = row["metric_name"].replace("drop_", "")
            value = row["value"]
            try:
                val = float(value)
                st.metric(f"Ø§ÙØª {metric}", f"{val:.3f}")
                if val > 0.05:  # 5% drop threshold
                    st.error(f"Ø§ÙØª Ø´Ø¯ÛŒØ¯ Ø¯Ø± {metric}!")
            except:
                st.metric(f"{metric} Ø§ÙØª", str(value))

def display_alerts(df):
    st.subheader("ğŸš¨ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…")
    
    latest = df.sort_values("timestamp").groupby("metric_name").tail(1)
    alerts = []
    
    # Check for extreme Wasserstein drift
    wasserstein_metrics = latest[latest["metric_name"].str.startswith("wasserstein_")]
    extreme_wasserstein = 0
    for _, row in wasserstein_metrics.iterrows():
        try:
            if float(row["value"]) > 100:
                extreme_wasserstein += 1
        except:
            pass
    
    if extreme_wasserstein > 0:
        alerts.append(f"ğŸ”´ {extreme_wasserstein} ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø¯Ø±ÛŒÙØª Ø¨Ø³ÛŒØ§Ø± Ø´Ø¯ÛŒØ¯ ÙˆØ§Ø³Ø±Ø´ØªØ§ÛŒÙ† Ù‡Ø³ØªÙ†Ø¯")

    
    # Check KS test results
    ks_metrics = latest[latest["metric_name"].str.startswith("ks_")]
    problematic_ks = 0
    for _, row in ks_metrics.iterrows():
        try:
            val = float(row["value"])
            if val < 0.001:  # KS near 0 = completely different
                problematic_ks += 1
        except:
            pass
    
    if problematic_ks > 0:
        alerts.append(f"ğŸŸ¡ {problematic_ks} ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø§Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ú©Ø§Ù…Ù„ ØªÙˆØ²ÛŒØ¹ Ù‡Ø³ØªÙ†Ø¯")
    
    # Check prediction drift
    pred_mean = latest[latest["metric_name"] == "PRED_mean_shift"]["value"].values
    if len(pred_mean) > 0:
        try:
            if abs(float(pred_mean[0])) > 50:
                alerts.append(f"ğŸ”´ Ø¨Ø§ÛŒØ§Ø³ Ø´Ø¯ÛŒØ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {float(pred_mean[0]):.1f}")
            elif abs(float(pred_mean[0])) > 10:
                alerts.append(f"ğŸŸ¡ Ø¨Ø§ÛŒØ§Ø³ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {float(pred_mean[0]):.1f}")
        except:
            pass
    
    # Check data quality
    missing_metrics = latest[latest["metric_name"].str.contains("dq_missing_")]
    high_missing = 0
    for _, row in missing_metrics.iterrows():
        try:
            if float(row["value"]) > 0.2:  # More than 20% missing
                high_missing += 1
        except:
            pass
    
    if high_missing > 0:
        alerts.append(f"ğŸŸ¡ {high_missing} ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø¨ÛŒØ´ Ø§Ø² Û²Û°Ùª Ø¯Ø§Ø¯Ù‡ Ú¯Ù…Ø´Ø¯Ù‡ Ù‡Ø³ØªÙ†Ø¯")
    
    # Display alerts
    if alerts:
        for alert in alerts:
            if "ğŸ”´" in alert:
                st.error(alert)
            elif "ğŸŸ¡" in alert:
                st.warning(alert)
            else:
                st.info(alert)
    else:
        st.success("âœ… Ù‡Ø´Ø¯Ø§Ø± Ø¨Ø­Ø±Ø§Ù†ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ â€” Ø³ÛŒØ³ØªÙ… Ù¾Ø§ÛŒØ¯Ø§Ø± Ø§Ø³Øª")

# ========== MAIN DASHBOARD ==========
st.set_page_config(layout="wide")
st.title("ğŸ§  Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù¾Ø§ÛŒØ´ Ù…Ø¯Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†")

# Sidebar
with st.sidebar:
    st.header("Settings")
    data_source = st.radio("Data Source", ["Metrics Store", "SQLite Database"])
    
    # Quick filters
    st.subheader("Filters")
    show_only_problems = st.checkbox("Show only problem metrics", value=False)
    
    # Info
    st.subheader("Info")
    st.info("""
    **Thresholds:**
    - KS < 0.01: Different distribution
    - Wasserstein > 10: Significant drift
    - Prediction shift > 10: Major bias
    """)

# Load data
if data_source == "Metrics Store":
    store = MetricsStore()
    df = store.load_history()
else:
    df = load_metrics()

if df.empty:
    st.warning("No monitoring data found yet.")
    st.stop()

# Convert timestamp
df["timestamp"] = pd.to_datetime(df["timestamp"])
latest_timestamp = df["timestamp"].max()
st.caption(f"Ø¢Ø®Ø±ÛŒÙ† Ø§Ù¾Ø¯ÛŒØª: {latest_timestamp}")

# ========== RISK OVERVIEW ==========
st.header("âš ï¸ Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ Ø±ÛŒØ³Ú© Ø³ÛŒØ³ØªÙ…")

# Get the ACTUAL risk score from your data (not calculate it)
latest = df.sort_values("timestamp").groupby("metric_name").tail(1)

# Look for system_risk_score in your data
risk_score_series = latest[latest["metric_name"] == "system_risk_score"]["value"]

if not risk_score_series.empty:
    try:
        # Use the risk score from your pipeline
        risk_score = float(risk_score_series.values[0])
    except:
        risk_score = 0
else:
    risk_score = 0

# Display risk gauge and status
col1, col2 = st.columns([2, 1])

with col1:
    st.plotly_chart(risk_gauge(risk_score), use_container_width=True)

with col2:
    # Risk status
    if risk_score < 30:
        st.success("ğŸŸ¢ Ø³ÛŒØ³ØªÙ… Ø³Ø§Ù„Ù… Ø§Ø³Øª")
    elif risk_score < 60:
        st.warning("ğŸŸ¡ Ø³ÛŒØ³ØªÙ… Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø±ÛŒØ³Ú©")
    else:
        st.error("ğŸ”´ ÙˆØ¶Ø¹ÛŒØª Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ…")
    
    st.metric("Risk Score", f"{risk_score:.1f}/100")
    
    # Get drift counts from your data
    static_drift = latest[latest["metric_name"] == "static_drifted_features"]["value"].values
    dynamic_drift = latest[latest["metric_name"] == "dynamic_drifted_features"]["value"].values
    
    st.subheader("Ø®Ù„Ø§ØµÙ‡ Ø¯Ø±ÛŒÙØª")
    if len(static_drift) > 0:
        st.write(f"ğŸ“Š Ø¯Ø±ÛŒÙØª Ø§ÛŒØ³ØªØ§: {int(static_drift[0])} ÙˆÛŒÚ˜Ú¯ÛŒ")
    if len(dynamic_drift) > 0:
        st.write(f"ğŸ“ˆ Ø¯Ø±ÛŒÙØª Ù¾ÙˆÛŒØ§: {int(dynamic_drift[0])} ÙˆÛŒÚ˜Ú¯ÛŒ")
    
    # Time info
    st.write(f"â° Ø¢Ø®Ø±ÛŒÙ† Ø§Ø¬Ø±Ø§: {latest_timestamp:%H:%M:%S}")

# ========== ALERTS SECTION ==========
display_alerts(df)

# ========== DRIFT METRICS ==========
display_drift_metrics(df)

# ========== PERFORMANCE METRICS ==========
display_performance_metrics(df)

# ========== TREND VISUALIZATIONS ==========
st.subheader("ğŸ“ˆ Ø±ÙˆÙ†Ø¯ ØªØºÛŒÛŒØ±Ø§Øª Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù†")

# Filter for risk score trend
risk_df = df[df["metric_name"] == "system_risk_score"].copy()
if not risk_df.empty:
    risk_df["numeric_value"] = risk_df["value"].apply(lambda x: float(x) if pd.notnull(x) else np.nan)
    
    fig = px.line(
        risk_df.dropna(subset=["numeric_value"]),
        x="timestamp",
        y="numeric_value",
        title="Ø±ÙˆÙ†Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ø±ÛŒØ³Ú© Ø³ÛŒØ³ØªÙ…",
        markers=True
    )
    fig.update_layout(yaxis_range=[0, 100])
    st.plotly_chart(fig, use_container_width=True)

# Add other metrics visualization
st.subheader("ğŸ“Š Ø±ÙˆÙ†Ø¯ Ø³Ø§ÛŒØ± Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§")

# Select metrics to visualize (excluding system_risk_score since we already showed it)
metric_options = sorted([m for m in df["metric_name"].unique() if m != "system_risk_score"])
selected_metrics = st.multiselect(
    "Select additional metrics to plot",
    options=metric_options,
    default=["PRED_mean_shift", "dynamic_perf_threshold"],
    max_selections=4
)

if selected_metrics:
    trend_df = df[df["metric_name"].isin(selected_metrics)].copy()
    
    # Convert values to numeric where possible
    def safe_convert(x):
        try:
            return float(x)
        except:
            return np.nan
    
    trend_df["numeric_value"] = trend_df["value"].apply(safe_convert)
    
    # Plot
    fig = px.line(
        trend_df.dropna(subset=["numeric_value"]),
        x="timestamp",
        y="numeric_value",
        color="metric_name",
        title="Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù†",
        markers=True
    )
    st.plotly_chart(fig, use_container_width=True)

# ========== RECENT DATA ==========
with st.expander("ğŸ“‹ Ø¢Ø®Ø±ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§"):
    # Show latest values
    latest_df = df.sort_values("timestamp").groupby("metric_name").tail(1)
    latest_df = latest_df.sort_values("metric_name")
    
    # Filter to show only problematic metrics if selected
    if show_only_problems:
        # Identify problematic metrics
        problem_metrics = []
        for _, row in latest_df.iterrows():
            metric = row["metric_name"]
            value = row["value"]
            
            try:
                num_val = float(value)
                if metric.startswith("ks_") and num_val < 0.01:
                    problem_metrics.append(metric)
                elif metric.startswith("wasserstein_") and num_val > 10:
                    problem_metrics.append(metric)
                elif metric.startswith("PRED_") and abs(num_val) > 10:
                    problem_metrics.append(metric)
                elif "missing" in metric and num_val > 0.2:
                    problem_metrics.append(metric)
            except:
                pass
        
        filtered_df = latest_df[latest_df["metric_name"].isin(problem_metrics)]
    else:
        filtered_df = latest_df
    
    st.dataframe(
        filtered_df[["metric_name", "value", "timestamp"]],
        height=300,
        use_container_width=True
    )
    
    # Download button
    csv = filtered_df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV",
        data=csv,
        file_name="latest_metrics.csv",
        mime="text/csv",
    )

# ========== FOOTER ==========
st.markdown("---")
st.caption("Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù¾Ø§ÛŒØ´ Ù…Ø¯Ù„ â€¢ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ ØµÙØ­Ù‡ Ø±Ø§ Ø±ÙØ±Ø´ Ú©Ù†ÛŒØ¯")