# ğŸ“Š Automated Detection of Data Drift and Model Performance Degradation

This repository contains a complete **Machine Learning Monitoring System** capable of:

âœ”ï¸ Detecting distribution changes in input data (Data Drift)  
âœ”ï¸ Detecting degradation in model performance after deployment  
âœ”ï¸ Logging metrics into a database  
âœ”ï¸ Visualizing results in an interactive dashboard  
âœ”ï¸ Sending alerts (email/notifications) when issues occur  
âœ”ï¸ Supporting multiple datasets (classification & regression)

This project was developed as part of a Bachelor's final project, and follows **industry-standard MLOps practices**.

---

## ğŸš€ Project Overview

Machine learning models often lose accuracy over time after deployment due to changing input data distributions or real-world conditions. This repository implements a modular monitoring pipeline that:

ğŸ”¹ Loads reference and current production data  
ğŸ”¹ Detects statistical drift using PSI (Population Stability Index)  
ğŸ”¹ Evaluates model performance over time  
ğŸ”¹ Stores metric history  
ğŸ”¹ Provides alerts when thresholds are exceeded  
ğŸ”¹ Shows results via an interactive dashboard

---

## ğŸ§± Repository Structure

```text
.
â”œâ”€â”€ Train model/                       # Artifacts for Telco model
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ feature_selector.pkl
â”‚   â”œâ”€â”€ all_features.csv
â”‚   â”œâ”€â”€ selected_features.csv
â”‚   â”œâ”€â”€ reference.csv
â”‚   â”œâ”€â”€ current.csv
â”‚   â””â”€â”€ baseline_metrics.csv
â”œâ”€â”€ Eth/                              # Artifacts for Ethereum model
â”‚   â”œâ”€â”€ eth_1min.csv
â”‚   â”œâ”€â”€ eth_1hour.csv
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ feature_selector.pkl
â”‚   â”œâ”€â”€ all_features.csv
â”‚   â”œâ”€â”€ selected_features.csv
â”‚   â”œâ”€â”€ reference.csv
â”‚   â”œâ”€â”€ current.csv
â”‚   â””â”€â”€ baseline_metrics.csv
â”œâ”€â”€ data_loader.py
â”œâ”€â”€ dataset_adapters.py
â”œâ”€â”€ drift_detection.py
â”œâ”€â”€ main.py
â”œâ”€â”€ model_monitor.py
â”œâ”€â”€ metrics_store.py
â”œâ”€â”€ alert_system.py
â”œâ”€â”€ config_loader.py
â”œâ”€â”€ dashboard.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Œ Features

### ğŸ“ˆ Automated Drift Detection

- Uses **Population Stability Index (PSI)** to measure distribution changes
- Detects drift for both numerical and categorical features
- Supports multiple dataset types through adapters

### ğŸ’¡ Performance Monitoring

- Computes performance metrics over production data:
  - Classification: *Accuracy, F1, Precision, Recall*
  - Regression: *MAE, RMSE, RÂ²*
- Compares against baseline (validation) metrics
- Logs historic performance

### ğŸ› ï¸ Modular and Extensible

- Adapter-based inputs â€” add new datasets easily
- Separate data loader for each dataset
- Config-driven architecture (`config.yaml`)
- Designed for multiple tasks (classification & regression)

### ğŸ“Š Dashboard

Built with **Streamlit** and **Plotly** to visualize:

- Drift trends over time
- Performance metric trends
- Alerts and status badges
- Raw metric logs

---

## ğŸ“„ Folder Descriptions

### `Train model/`

Contains Telco customer churn artifacts from training:

- `model.pkl`: Trained classification model  
- `feature_selector.pkl`: Feature selector  
- `reference.csv`: Reference (training) data  
- `current.csv`: Latest data  
- `all_features.csv`: One-hot features  
- `selected_features.csv`: Post-selection features  
- `baseline_metrics.csv`: Validation reference metrics 

---

### `Eth/`

Contains Ethereum price model artifacts:

- Raw datasets (`eth_1min.csv`, `eth_1hour.csv`)
- Trained regression model and selector
- Reference & current production splits
- Feature lists & baseline metrics

---

## ğŸ§ª How to Train Models

### â˜‘ï¸ Train Telco Model

```bash
python "Train model/train_model.py"
```

### â˜‘ï¸ Train Ethereum Model (1-hour)

```bash
python Eth/train_model.py
```

This will generate all required artifacts for monitoring.

---

## â–¶ï¸ Running the Monitoring Pipeline

Configure your dataset in `config.yaml`:

```yaml
app:
  dataset_name: "ethereum"         # "telco" or "ethereum"
model:
  path: "Eth/model.pkl"
  baseline_metrics_path: "Eth/baseline_metrics.csv"
monitoring:
  drift_threshold: 0.2
  performance_drop_threshold: 0.05
alerts:
  email_enabled: false
```

Then run:

```bash
python main.py
```

This script performs:

* Drift Detection
* Performance Evaluation
* Metrics Logging
* Optional Alerts

---

## ğŸ“Š Dashboard Visualization

Start the dashboard with:

```bash
streamlit run dashboard.py
```

Access it at:

```
http://localhost:8501
```

The dashboard displays:

âœ” Drift heatmaps
âœ” Performance curves
âœ” Current status badges
âœ” Raw metric logs

---

## ğŸ“© Alerting & Notifications

The system supports email alerts via SMTP (e.g., Gmail). Use an **App Password** for security.

Configure in `config.yaml`:

```yaml
alerts:
  email_enabled: true
  sender_email: "example@gmail.com"
  sender_password: "app_password_here"
  receiver_email: "notify@domain.com"
```

Alerts trigger when:

âœ” Drift > threshold
âœ” Performance drop > threshold

---

## ğŸ“ Example Config (config.yaml)

```yaml
app:
  dataset_name: "telco"
model:
  path: "Train model/model.pkl"
  baseline_metrics_path: "Train model/baseline_metrics.csv"
monitoring:
  drift_threshold: 0.2
  performance_drop_threshold: 0.05
alerts:
  email_enabled: false
dashboard:
  host: "localhost"
  port: 8501
```

---

## ğŸ§  Why This Matters

This system demonstrates:

âœ” Real-time model monitoring
âœ” Adaptation for multiple model types
âœ” Modular, extensible pipeline
âœ” Data and model drift handling
âœ” End-to-end visualization

Itâ€™s designed for **production readiness** and academic research use.

---

## ğŸ“¦ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ“š Cite / References

If using this in academic work, reference:

âœ” Population Stability Index (PSI) for drift
âœ” Regression & Classification monitoring metrics

---

## ğŸ“¬ Contact

âœ¨ Created by **Tina Hafezi**
ğŸ“ Bachelor Final Project â€” ML Model Monitoring System
